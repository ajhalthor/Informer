{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we implement the self distillation part of the Informer Encoder seen [here](https://github.com/zhouhaoyi/Informer2020/blob/main/models/encoder.py#L5) in the original code"
      ],
      "metadata": {
        "id": "MluT6TSlT59j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "wPtAViSRTbZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let `y` be the output of the ProbSparse attention + the rest of the encoder transformation logic."
      ],
      "metadata": {
        "id": "7FFu0VUGTxo8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bo2LW4KTLaW"
      },
      "outputs": [],
      "source": [
        "y = torch.tensor(\n",
        "    [[[-0.4279, -0.3064, -0.4279, -0.4279, -0.7816, -0.2918, -0.4279, -0.1300, -0.2762, -0.3435],\n",
        "      [-0.3153, -0.2792, -0.3153, -0.3153, -0.0058, -0.1535, -0.3153,  0.2457, -0.4200, -0.4456],\n",
        "      [ 0.2137,  0.1333,  0.2137,  0.2137,  0.3584,  0.0689,  0.2137, -0.0486,  0.1854,  0.2332],\n",
        "      [-0.0565, -0.0637, -0.0565, -0.0565, -0.1396, -0.0519, -0.0565, -0.2497, -0.0881, -0.0858]\n",
        "]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, d_model, L_Q = y.shape\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiFp_VXPTevI",
        "outputId": "691df56b-d249-4455-82c7-ec8a003bbd53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.transpose(1, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pylkHYjoVTC1",
        "outputId": "a46d2774-4617-43e6-d3ea-f9acfa9040fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.4279, -0.3153,  0.2137, -0.0565],\n",
              "         [-0.3064, -0.2792,  0.1333, -0.0637],\n",
              "         [-0.4279, -0.3153,  0.2137, -0.0565],\n",
              "         [-0.4279, -0.3153,  0.2137, -0.0565],\n",
              "         [-0.7816, -0.0058,  0.3584, -0.1396],\n",
              "         [-0.2918, -0.1535,  0.0689, -0.0519],\n",
              "         [-0.4279, -0.3153,  0.2137, -0.0565],\n",
              "         [-0.1300,  0.2457, -0.0486, -0.2497],\n",
              "         [-0.2762, -0.4200,  0.1854, -0.0881],\n",
              "         [-0.3435, -0.4456,  0.2332, -0.0858]]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The records with similar values correspond to the non-chosen queries.\n",
        "\n",
        "If the 10 queries, 6 are active. Hence 4 are lazy and so we have 4 redundencies here.\n",
        "\n",
        "Our goal is to now remove these redundencies. And we do so with a process called \"self attention distillation\".\n",
        "\n",
        "In chemistry, distillation is the process extraction and concentration of a compount from a mixture.\n",
        "\n",
        "In much the same way, we perform distillation here to extract the active queries from the lazy queries.\n",
        "\n",
        "In practice, this is done adding a convolution, batch normalization, activation and max pooling.\n",
        "\n",
        "This is the mathematical representation of the distillation process\n",
        "\n",
        "$$\n",
        "y = \\text{MaxPool(ELU(BatchNorm(Conv(y))))}\n",
        "$$"
      ],
      "metadata": {
        "id": "Vswp492VV1Hb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Conv1D"
      ],
      "metadata": {
        "id": "FjWYvu8gKUZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "![Conv 1D](https://discuss.pytorch.org/uploads/default/original/3X/5/f/5faf64f4eb86dd37121774c720877b1d44f7f617.gif)"
      ],
      "metadata": {
        "id": "GylZdZ6mmU6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "^ Source: https://discuss.pytorch.org/t/1d-convolution-on-1d-data/54661/11"
      ],
      "metadata": {
        "id": "KrFPNwXqmtv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "downConv = nn.Conv1d(\n",
        "    in_channels=d_model,\n",
        "    out_channels=d_model,\n",
        "    kernel_size=3,\n",
        "    padding=1,\n",
        "    padding_mode='circular'\n",
        ")\n",
        "downConv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va55z9oCVkxG",
        "outputId": "ea516edd-fc04-4cea-ef38-3418a5f46fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = downConv(y)\n",
        "y.transpose(1, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpNxTEYCWW23",
        "outputId": "1ff129d3-ecd8-4782-c000-dcbcf26cf517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1781, -0.2201, -0.3053, -0.0687],\n",
              "         [ 0.1251, -0.2603, -0.3470, -0.0435],\n",
              "         [ 0.1565, -0.2149, -0.3138, -0.0751],\n",
              "         [ 0.0428, -0.4520, -0.3234, -0.1159],\n",
              "         [ 0.3373, -0.1578, -0.3097, -0.1270],\n",
              "         [ 0.1785, -0.2392, -0.4275, -0.0581],\n",
              "         [ 0.2518, -0.1709, -0.1564, -0.2870],\n",
              "         [ 0.1757, -0.1858, -0.4516,  0.0660],\n",
              "         [ 0.2008, -0.0368, -0.2885, -0.1068],\n",
              "         [ 0.1144, -0.2748, -0.2837, -0.0460]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMn5Cv3dlUyf",
        "outputId": "65b37a01-e313-4c4f-e74a-95701194d946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is happening in convolution 1D?**\n",
        "- This means we should have 4 (C_out) kernels with each kernel having a shape 3 x 4 (kernel_size x C_in).\n",
        "- So for the given input 1 x 4 x 10, we slide one 3x4 kernel along the time dimension (10).\n",
        "- In the first iteration of convolution, the 3x4 kernel is convolved with the first 3 timestamps.\n",
        "- So when convolving the 3x4 kernel with 3x4 slice of the input matrix, we end up with a single number.\n",
        "- We then slide the kernel, perform the convolutions and end up with a single number each time.\n",
        "- The once the kernel has slid to the end of the time dimension, we would have ended up with a 1 x 10 dimensional vector.\n",
        "- But there should be 4 output channels (C_out = 4).\n",
        "- Hence performing the similar convolution along the time dimension for each of these kernels leads to 4 1x10 matricies. Or a 4 x 10 matrix.\n",
        "\n",
        "**Effectively as a result of this operation**:\n",
        "- The shape is not changed\n",
        "- The vectors now have a sense of local context becuase of the kernel size = 3."
      ],
      "metadata": {
        "id": "aTK_afQAldsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is an implementation of Conv1D"
      ],
      "metadata": {
        "id": "H2ONBRtY4Ty7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "        super(CustomConv1d, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.weight = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size))\n",
        "        self.bias = nn.Parameter(torch.randn(out_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if self.padding > 0:\n",
        "            x = F.pad(x, (self.padding, self.padding))\n",
        "\n",
        "        batch_size, in_channels, sequence_length = x.shape\n",
        "        out_length = (sequence_length - self.kernel_size) // self.stride + 1\n",
        "\n",
        "        output = torch.zeros((batch_size, self.out_channels, out_length))\n",
        "\n",
        "        # Perform the convolution operation\n",
        "        for b in range(batch_size):\n",
        "            for o in range(self.out_channels):\n",
        "                for i in range(0, sequence_length - self.kernel_size + 1, self.stride):\n",
        "                    region = x[b, :, i:i+self.kernel_size]\n",
        "                    output[b, o, i // self.stride] = torch.sum(region * self.weight[o, :, :]) + self.bias[o]\n",
        "\n",
        "        return output\n",
        "\n",
        "kernel_size = 3\n",
        "in_channels = 4\n",
        "out_channels = 4\n",
        "\n",
        "custom_conv1d = CustomConv1d(\n",
        "    in_channels=in_channels,\n",
        "    out_channels=out_channels,\n",
        "    kernel_size=kernel_size,\n",
        "    stride=1,\n",
        "    padding=1\n",
        ")\n",
        "x = torch.randn(1, in_channels, 10) # Example input with (batch_size, in_channels, sequence_length)\n",
        "print(\"Input Shape:\", x.shape)\n",
        "x = custom_conv1d(x)\n",
        "print(\"Output Shape:\", x.shape)\n",
        "print(\"Output:\", x.transpose(1, -1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy1W_qfxJmE8",
        "outputId": "6816bac6-bae2-42e5-f235-1314c8cd4c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Shape: torch.Size([1, 4, 10])\n",
            "Output Shape: torch.Size([1, 4, 10])\n",
            "Output: tensor([[[ 3.0105, -0.3359,  4.7515,  1.9616],\n",
            "         [-4.4009,  1.3132,  0.4764, -2.2379],\n",
            "         [-1.0181,  1.4909,  1.6197,  1.8993],\n",
            "         [ 3.6055, -1.2282,  1.0855, -2.3256],\n",
            "         [ 1.2337, -0.3768, -2.1121, -0.8444],\n",
            "         [-1.1882, -0.1815, -2.2545,  2.6530],\n",
            "         [ 7.1665, -0.6749, -1.3431,  5.7508],\n",
            "         [ 0.1426, -2.5285, -1.1750,  0.2404],\n",
            "         [-1.7602,  2.9976,  2.5532,  4.9390],\n",
            "         [ 1.5305, -0.7658, -0.1509, -3.7880]]], grad_fn=<TransposeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BatchNorm1D"
      ],
      "metadata": {
        "id": "XXox5d9H5x9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm = nn.BatchNorm1d(d_model)\n",
        "norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oujQaeroaKR_",
        "outputId": "15f9fb52-97b3-4bea-ecff-3fc0ec6b5620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = norm(y)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZcUY21pDnBK",
        "outputId": "03162141-b556-4170-c128-84920480709d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0260, -0.6752, -0.2591, -1.7654,  2.1353,  0.0313,  1.0030,\n",
              "          -0.0055,  0.3272, -0.8175],\n",
              "         [ 0.0113, -0.3901,  0.0636, -2.3083,  0.6347, -0.1790,  0.5033,\n",
              "           0.3547,  1.8452, -0.5353],\n",
              "         [ 0.2003, -0.3423,  0.0891, -0.0349,  0.1433, -1.3888,  2.1361,\n",
              "          -1.7024,  0.4185,  0.4810],\n",
              "         [ 0.2078,  0.5062,  0.1316, -0.3516, -0.4835,  0.3328, -2.3792,\n",
              "           1.8039, -0.2442,  0.4762]]], grad_fn=<NativeBatchNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.transpose(1, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sneBnVUT0CoH",
        "outputId": "7f25e612-74ed-484c-b491-046e1d348607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0260,  0.0113,  0.2003,  0.2078],\n",
              "         [-0.6752, -0.3901, -0.3423,  0.5062],\n",
              "         [-0.2591,  0.0636,  0.0891,  0.1316],\n",
              "         [-1.7654, -2.3083, -0.0349, -0.3516],\n",
              "         [ 2.1353,  0.6347,  0.1433, -0.4835],\n",
              "         [ 0.0313, -0.1790, -1.3888,  0.3328],\n",
              "         [ 1.0030,  0.5033,  2.1361, -2.3792],\n",
              "         [-0.0055,  0.3547, -1.7024,  1.8039],\n",
              "         [ 0.3272,  1.8452,  0.4185, -0.2442],\n",
              "         [-0.8175, -0.5353,  0.4810,  0.4762]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpj9gFH8DtZc",
        "outputId": "647b36f4-5d9d-4ebf-bed5-945d57b7d9fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBatchNorm1d(nn.Module):\n",
        "    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True):\n",
        "        super(CustomBatchNorm1d, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.affine = affine\n",
        "\n",
        "        # Initialize learnable parameters gamma and beta if affine is True\n",
        "        if self.affine:\n",
        "            self.gamma = nn.Parameter(torch.ones(num_features))\n",
        "            self.beta = nn.Parameter(torch.zeros(num_features))\n",
        "        else:\n",
        "            self.register_parameter('gamma', None)\n",
        "            self.register_parameter('beta', None)\n",
        "\n",
        "        # Initialize running mean and running variance\n",
        "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
        "        self.register_buffer('running_var', torch.ones(num_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training:\n",
        "            # Compute batch mean and variance\n",
        "            batch_mean = x.mean(dim=[0, 2])\n",
        "            batch_var = x.var(dim=[0, 2], unbiased=False)\n",
        "\n",
        "            # Update running mean and variance\n",
        "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * batch_mean\n",
        "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * batch_var\n",
        "        else:\n",
        "            batch_mean = self.running_mean\n",
        "            batch_var = self.running_var\n",
        "\n",
        "        # Normalize input\n",
        "        x_hat = (x - batch_mean[None, :, None]) / torch.sqrt(batch_var[None, :, None] + self.eps)\n",
        "\n",
        "        # Apply learnable parameters if affine is True\n",
        "        if self.affine:\n",
        "            x_hat = self.gamma[None, :, None] * x_hat + self.beta[None, :, None]\n",
        "\n",
        "        return x_hat\n",
        "\n",
        "# Create a custom BatchNorm1d layer for 4 features\n",
        "batch_norm = CustomBatchNorm1d(4)\n",
        "batch_norm.train() # Set to training mode\n",
        "optimizer = optim.SGD(batch_norm.parameters(), lr=0.01) # Create an optimizer\n",
        "\n",
        "# Example training loop\n",
        "for i in range(100):\n",
        "    x = torch.randn(10, 4, 10) + torch.randn(10, 4, 10) * 0.5  # Add some noise to the tensor\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "    output = batch_norm(x)\n",
        "    loss = ((output - x) ** 2).mean()  # Mean squared error for demonstration\n",
        "    loss.backward()  # Backpropagate the loss\n",
        "    optimizer.step()  # Update the parameters\n",
        "\n",
        "batch_norm.eval()  # Switch to evaluation mode\n",
        "\n",
        "# Example input tensor with shape 1 x 4 x 10 (batch_size, num_features, sequence_length)\n",
        "x = torch.randn(1, 4, 10) + torch.randn(1, 4, 10) * 10  # Add some noise to the tensor\n",
        "print(f\"Input x = {x.transpose(1, -1)}\")\n",
        "# Apply custom Batch Normalization\n",
        "x_normalized = batch_norm(x)\n",
        "print(\"Normalized Output:\", x_normalized.transpose(1, -1))\n",
        "print(f\"Learned parameters: gamma = {batch_norm.gamma}, beta = {batch_norm.beta}\")"
      ],
      "metadata": {
        "id": "Ghmbj63LJGcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ae80b8-3095-4d56-cea6-27acb81fdc7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input x = tensor([[[ -3.1063,   0.1304,  17.9303,  -8.4741],\n",
            "         [ 11.1877,   6.3469,  -9.0957,  -1.5174],\n",
            "         [-14.7600,  10.8687,  26.7499,   7.0928],\n",
            "         [  1.1092,  -3.5419,   2.1124,   1.7924],\n",
            "         [-19.9245,   2.3600,  -3.9004,   9.1631],\n",
            "         [ 14.7265,   0.9318,  -2.3177,   3.8916],\n",
            "         [  2.2570,  12.1360,  -8.3831,  -0.6496],\n",
            "         [  8.5910,   8.0781,   6.2588,   2.6054],\n",
            "         [  3.8296,   8.5246,  10.7348, -11.1375],\n",
            "         [-17.7490, -11.3412,   7.7679,  15.6306]]])\n",
            "Normalized Output: tensor([[[ -2.8880,   0.1589,  16.7962,  -7.8655],\n",
            "         [ 10.3153,   6.0642,  -8.5759,  -1.4109],\n",
            "         [-13.6525,  10.3597,  25.0761,   6.5779],\n",
            "         [  1.0058,  -3.3296,   1.9464,   1.6601],\n",
            "         [-18.4229,   2.2769,  -3.6985,   8.4988],\n",
            "         [ 13.5840,   0.9202,  -2.2126,   3.6078],\n",
            "         [  2.0660,  11.5635,  -7.9068,  -0.6057],\n",
            "         [  7.9168,   7.7088,   5.8390,   2.4144],\n",
            "         [  3.5187,   8.1330,  10.0411, -10.3367],\n",
            "         [-16.4134, -10.7385,   7.2557,  14.4995]]],\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "Learned parameters: gamma = Parameter containing:\n",
            "tensor([1.0469, 1.0465, 1.0491, 1.0450], requires_grad=True), beta = Parameter containing:\n",
            "tensor([ 0.0090, -0.0051,  0.0070, -0.0011], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is BatchNorm 1D doing**\n",
        "- During training, we compute a running mean and variance of each feature across batches.\n",
        "- During inference, we normalize input using these running mean and variance.  \n",
        "\n",
        "**Effectively:**\n",
        "- Does not change shape of input tensor\n",
        "- Overall, improves for faster and more stable training"
      ],
      "metadata": {
        "id": "g_N5Vd7cageC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 ELU"
      ],
      "metadata": {
        "id": "vXE5Mf_SaJ8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Elu](https://armandolivares.tech/wp-content/uploads/2022/09/elu-1.png)"
      ],
      "metadata": {
        "id": "_NbFB4iUxvrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activation = nn.ELU()\n",
        "activation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrxuqKFQx0-Q",
        "outputId": "b676288d-ce70-4ddf-f235-2f7dee1200f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ELU(alpha=1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.exp(-0.6752) - 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77_YvCEQygl1",
        "outputId": "bd214d4e-556a-4fe7-b3c8-3570e7944d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.49094540049412283"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.transpose(1, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC89aezK0I8D",
        "outputId": "5a22d34c-3e80-438c-b358-4fa1f127f16e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0260,  0.0113,  0.2003,  0.2078],\n",
              "         [-0.6752, -0.3901, -0.3423,  0.5062],\n",
              "         [-0.2591,  0.0636,  0.0891,  0.1316],\n",
              "         [-1.7654, -2.3083, -0.0349, -0.3516],\n",
              "         [ 2.1353,  0.6347,  0.1433, -0.4835],\n",
              "         [ 0.0313, -0.1790, -1.3888,  0.3328],\n",
              "         [ 1.0030,  0.5033,  2.1361, -2.3792],\n",
              "         [-0.0055,  0.3547, -1.7024,  1.8039],\n",
              "         [ 0.3272,  1.8452,  0.4185, -0.2442],\n",
              "         [-0.8175, -0.5353,  0.4810,  0.4762]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = activation(y)\n",
        "y.transpose(1, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rureAWxrX8Rj",
        "outputId": "1bad1529-5562-45ee-d747-a3c533847274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0260,  0.0113,  0.2003,  0.2078],\n",
              "         [-0.4910, -0.3230, -0.2898,  0.5062],\n",
              "         [-0.2282,  0.0636,  0.0891,  0.1316],\n",
              "         [-0.8289, -0.9006, -0.0343, -0.2964],\n",
              "         [ 2.1353,  0.6347,  0.1433, -0.3834],\n",
              "         [ 0.0313, -0.1639, -0.7506,  0.3328],\n",
              "         [ 1.0030,  0.5033,  2.1361, -0.9074],\n",
              "         [-0.0055,  0.3547, -0.8177,  1.8039],\n",
              "         [ 0.3272,  1.8452,  0.4185, -0.2167],\n",
              "         [-0.5585, -0.4145,  0.4810,  0.4762]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomELU(nn.Module):\n",
        "    def __init__(self, alpha=1.0):\n",
        "        super(CustomELU, self).__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.where(x >= 0, x, self.alpha * (torch.exp(x) - 1))\n",
        "\n",
        "elu = CustomELU(alpha=1.0)\n",
        "x = torch.randn(1, 4, 10) # Example input with (batch_size, in_channels, sequence_length)\n",
        "print(\"Input:\", x.transpose(1, -1))\n",
        "x = elu(x)\n",
        "print(\"Output:\", x.transpose(1, -1))"
      ],
      "metadata": {
        "id": "FIvJA-erJ_W7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a499439-fc2d-49f1-a321-1f2e0b29b067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([[[ 1.3933, -0.1014,  0.1263, -1.4776],\n",
            "         [-0.6408,  1.3629,  1.3665, -1.3499],\n",
            "         [-0.4621,  0.7703,  1.5326, -0.4740],\n",
            "         [-0.0628, -0.3342, -2.3160,  0.1374],\n",
            "         [-0.1057, -0.7446, -0.0148, -1.0766],\n",
            "         [ 1.2083,  1.0100,  0.5466, -0.8150],\n",
            "         [ 1.3274, -1.4542,  2.2502, -1.9747],\n",
            "         [-0.1835,  1.1149, -1.2386,  1.8667],\n",
            "         [ 0.2250, -0.6249,  0.7311,  1.9726],\n",
            "         [-0.9925, -0.3995, -0.1549,  0.7506]]])\n",
            "Output: tensor([[[ 1.3933, -0.0965,  0.1263, -0.7718],\n",
            "         [-0.4731,  1.3629,  1.3665, -0.7407],\n",
            "         [-0.3701,  0.7703,  1.5326, -0.3775],\n",
            "         [-0.0608, -0.2841, -0.9013,  0.1374],\n",
            "         [-0.1003, -0.5251, -0.0147, -0.6592],\n",
            "         [ 1.2083,  1.0100,  0.5466, -0.5573],\n",
            "         [ 1.3274, -0.7664,  2.2502, -0.8612],\n",
            "         [-0.1676,  1.1149, -0.7102,  1.8667],\n",
            "         [ 0.2250, -0.4647,  0.7311,  1.9726],\n",
            "         [-0.6294, -0.3294, -0.1435,  0.7506]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is ELU doing?**\n",
        "- For each element, it performs a linear or exponential transformation\n",
        "\n",
        "**Effectively**\n",
        "- The shape does not change\n",
        "- Like other activation functions, it introduces non-linearity so the network can learn complex patterns\n",
        "- Unlike ReLU, it prevents dead neurons and vanishing gradients."
      ],
      "metadata": {
        "id": "GrWE0HuvyrKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 MaxPooling"
      ],
      "metadata": {
        "id": "TTUybD0n3dhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxPool = nn.MaxPool1d(\n",
        "    kernel_size=3,\n",
        "    stride=2,\n",
        "    padding=1\n",
        ")\n",
        "maxPool"
      ],
      "metadata": {
        "id": "t_ao6ShiWkaH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df042120-6a92-414a-ef71-453c1683d219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.transpose(1, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMivS1oQz1RK",
        "outputId": "00ddc649-7bad-4fb9-d3f5-2834159eebaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0260,  0.0113,  0.2003,  0.2078],\n",
              "         [-0.4910, -0.3230, -0.2898,  0.5062],\n",
              "         [-0.2282,  0.0636,  0.0891,  0.1316],\n",
              "         [-0.8289, -0.9006, -0.0343, -0.2964],\n",
              "         [ 2.1353,  0.6347,  0.1433, -0.3834],\n",
              "         [ 0.0313, -0.1639, -0.7506,  0.3328],\n",
              "         [ 1.0030,  0.5033,  2.1361, -0.9074],\n",
              "         [-0.0055,  0.3547, -0.8177,  1.8039],\n",
              "         [ 0.3272,  1.8452,  0.4185, -0.2167],\n",
              "         [-0.5585, -0.4145,  0.4810,  0.4762]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = maxPool(y)\n",
        "y.transpose(1, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIujsTcaX00T",
        "outputId": "c58b0a82-20ae-4c02-ec7d-f3b508c5e316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0260,  0.0113,  0.2003,  0.5062],\n",
              "         [-0.2282,  0.0636,  0.0891,  0.5062],\n",
              "         [ 2.1353,  0.6347,  0.1433,  0.3328],\n",
              "         [ 1.0030,  0.5033,  2.1361,  1.8039],\n",
              "         [ 0.3272,  1.8452,  0.4810,  1.8039]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCy0TI6UX2-Y",
        "outputId": "298ccce8-bcb8-44c9-cbf8-b4d5d411d34f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What happens during max pooling 1D?**\n",
        "- kernel_size = 3, stride = 2, padding = 1\n",
        "- A window of 3 (kernel size) is slid along the time dimension on each of the 4 dimensions.\n",
        "- When sliding, the window skips over 2 items (stride)\n",
        "- When sliding, there is a padding before and after the time dimension (padding).\n",
        "- With the 1 x 4 x 10 input, we slide the max pool window on the first of the 4 dimensions across the first 3 timesteps, take the max and slide the window over. This row will lead to 1 x 5 max values\n",
        "- Since the vector size is 4, we iterate the max pool window to get 4 of these 1x5 max values.\n",
        "- The result is 1 x 4 x 5 (time dimension) values.\n",
        "\n",
        "**Effectively**\n",
        "- max pooling slices the time dimension in half\n",
        "- max pooling will allow us to only select the more \"active\" queries and leave out the more redundant \"lazy\" queries."
      ],
      "metadata": {
        "id": "Vj1iPd5dYL28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMaxPool1d(nn.Module):\n",
        "    def __init__(self, kernel_size, stride=None, padding=0):\n",
        "        super(CustomMaxPool1d, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride if stride is not None else kernel_size\n",
        "        self.padding = padding\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if self.padding > 0:\n",
        "            x = F.pad(x, (self.padding, self.padding))\n",
        "\n",
        "        batch_size, in_channels, sequence_length = x.shape\n",
        "        out_length = (sequence_length - self.kernel_size) // self.stride + 1\n",
        "        output = torch.zeros((batch_size, in_channels, out_length))\n",
        "\n",
        "        # Perform the max pooling operation manually\n",
        "        for b in range(batch_size):\n",
        "            for c in range(in_channels):\n",
        "                for i in range(0, sequence_length - self.kernel_size + 1, self.stride):\n",
        "                    region = x[b, c, i:i+self.kernel_size]\n",
        "                    output[b, c, i // self.stride] = torch.max(region)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Create a MaxPool1d layer\n",
        "maxpool1d = CustomMaxPool1d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "# Example input tensor with shape (batch_size, in_channels, sequence_length)\n",
        "x = torch.tensor(\n",
        "    [[[1.0, 2.0, 3.0, 4.0, 5.0],\n",
        "      [5.0, 4.0, 3.0, 2.0, 1.0]]]\n",
        ")\n",
        "print(f\"Input  ({x.shape}) : {x} \")\n",
        "x = maxpool1d(x)\n",
        "print(f\"Output ({x.shape}) :\", x)"
      ],
      "metadata": {
        "id": "FiVRmsy2YJTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "878c9efb-40b7-4cc5-9bb6-50eba9724783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input  (torch.Size([1, 2, 5])) : tensor([[[1., 2., 3., 4., 5.],\n",
            "         [5., 4., 3., 2., 1.]]]) \n",
            "Output (torch.Size([1, 2, 2])) : tensor([[[2., 4.],\n",
            "         [5., 3.]]])\n"
          ]
        }
      ]
    }
  ]
}