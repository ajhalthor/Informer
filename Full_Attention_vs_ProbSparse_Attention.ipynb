{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "k1ilqNbCRKSW",
        "F_OqOTZQT-Z5",
        "aEzTT6SLXxcN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will compare Full Attention to a sparse attention technique used in long time series problems to make the operations quick."
      ],
      "metadata": {
        "id": "LDsfqAdyQ_xJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Attention"
      ],
      "metadata": {
        "id": "k1ilqNbCRKSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "$$\n",
        "\\text{Full Attention} = \\text{softmax} \\bigg( \\frac{Q.K^T}{\\sqrt d_q} \\bigg).V\n",
        "$$\n",
        "\n",
        "Let's start with defining query, keys and value vectors."
      ],
      "metadata": {
        "id": "IhXx-vGbYAfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from math import sqrt"
      ],
      "metadata": {
        "id": "uzq3h4fLRvEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_heads = 1 # Assume single head attention\n",
        "batch_size = 1 # Assume single batch size\n",
        "sequence_length = L_Q = L_K = L_V = 10 # Number of datapoints passed in parallel\n",
        "d_model = 4 # Number of features per data point\n",
        "\n",
        "d_k = d_model // n_heads\n",
        "d_v = d_model // n_heads\n",
        "d_q = d_model // n_heads\n",
        "\n",
        "Q = torch.randn( (batch_size, L_Q, n_heads, d_q) )\n",
        "K = torch.randn( (batch_size, L_K, n_heads, d_k) )\n",
        "V = torch.randn( (batch_size, L_V, n_heads, d_v) )"
      ],
      "metadata": {
        "id": "GMsrIXeQRApS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q.shape, K.shape, V.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JHbw3KsR_TT",
        "outputId": "03c21075-f9d9-4b1e-86b9-4f92ecc4ff17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 10, 1, 4]),\n",
              " torch.Size([1, 10, 1, 4]),\n",
              " torch.Size([1, 10, 1, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = torch.einsum(\"blhe,bshe->bhls\", Q, K)\n",
        "scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQw856rUSMDt",
        "outputId": "8edaf91f-a1ca-447b-9f6d-4cebd1878f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.einsum` is a powerful function that could perform addition, multiplication and rearrangement of tensors. You see this in the otiginal informer code."
      ],
      "metadata": {
        "id": "SujypSl-SGYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voYg4GYHSCRA",
        "outputId": "75cb2d72-e03d-4ef1-a7ad-2dad58019cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.9837,  1.0102, -1.4656, -1.8151, -0.5829,  0.0494,  0.7742,\n",
              "           -1.3344,  1.6809,  0.0954],\n",
              "          [-1.2752, -0.3817, -0.3368,  1.9013,  0.3895, -0.1814, -1.2206,\n",
              "           -0.5959, -2.7997,  0.4464],\n",
              "          [-1.3294, -1.3175,  1.4667,  1.1584,  1.3219,  0.5197,  0.1335,\n",
              "            0.7488, -1.5054,  0.9336],\n",
              "          [ 0.2817,  0.3830,  1.2102, -0.4990, -0.8077,  0.0072,  0.1867,\n",
              "            1.2884,  1.6660, -0.7949],\n",
              "          [ 0.1928,  0.0379,  2.0728,  1.9656, -1.4251, -0.9910, -1.8786,\n",
              "            3.0749, -0.0796, -2.4746],\n",
              "          [ 2.7199, -1.1410,  2.3034, -1.9675,  0.5378,  0.0364,  1.9027,\n",
              "            3.4813,  4.1183, -1.5084],\n",
              "          [-0.3402,  0.4161, -3.1723,  0.3304,  0.4489, -0.1852, -0.5669,\n",
              "           -3.2813, -2.4455,  1.2121],\n",
              "          [-4.0858, -0.1368,  2.9327,  0.5041,  0.4458,  1.8001,  0.7948,\n",
              "           -0.0374, -0.7481,  2.5106],\n",
              "          [ 2.5345,  1.6985,  0.1427, -0.0807, -3.0892, -1.6868, -1.6755,\n",
              "            2.3248,  2.6323, -3.8829],\n",
              "          [-1.9989, -0.4474, -1.7254,  2.0710,  1.0938,  0.0751, -1.1806,\n",
              "           -2.5052, -4.3661,  1.7290]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "`scores`: Each element in this matrix is a number that corresponds to the affinity of a query i with a key j.\n",
        "\n",
        "This matrix multiplcation requires 4 multiplcations and 3 additions for every 10 x 10 spot.\n",
        "\n",
        "Hence, this matrix multiplication has `O(L_Q * L_K)` multiplication operations.\n",
        "\n",
        "This is quadratic in the number of samples in the time series sequence."
      ],
      "metadata": {
        "id": "IiCdYPg2fvyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`scores` can be computed with the equivalent matrix multiplication of the query and key vectors"
      ],
      "metadata": {
        "id": "SMlb5Oh9SwfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(Q.squeeze(0, 2), K.squeeze(0, 2).T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfGFdB_ZSpIg",
        "outputId": "0dfa5142-4824-4959-aa58-ae2bdba3467b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9837,  1.0102, -1.4656, -1.8151, -0.5829,  0.0494,  0.7742, -1.3344,\n",
              "          1.6809,  0.0954],\n",
              "        [-1.2752, -0.3817, -0.3368,  1.9013,  0.3895, -0.1814, -1.2206, -0.5959,\n",
              "         -2.7997,  0.4464],\n",
              "        [-1.3294, -1.3175,  1.4667,  1.1584,  1.3219,  0.5197,  0.1335,  0.7488,\n",
              "         -1.5054,  0.9336],\n",
              "        [ 0.2817,  0.3830,  1.2102, -0.4990, -0.8077,  0.0072,  0.1867,  1.2884,\n",
              "          1.6660, -0.7949],\n",
              "        [ 0.1928,  0.0379,  2.0728,  1.9656, -1.4251, -0.9910, -1.8786,  3.0749,\n",
              "         -0.0796, -2.4746],\n",
              "        [ 2.7199, -1.1410,  2.3034, -1.9675,  0.5378,  0.0364,  1.9027,  3.4813,\n",
              "          4.1183, -1.5084],\n",
              "        [-0.3402,  0.4161, -3.1723,  0.3304,  0.4489, -0.1852, -0.5669, -3.2813,\n",
              "         -2.4455,  1.2121],\n",
              "        [-4.0858, -0.1368,  2.9327,  0.5041,  0.4458,  1.8001,  0.7948, -0.0374,\n",
              "         -0.7481,  2.5106],\n",
              "        [ 2.5345,  1.6985,  0.1427, -0.0807, -3.0892, -1.6868, -1.6755,  2.3248,\n",
              "          2.6323, -3.8829],\n",
              "        [-1.9989, -0.4474, -1.7254,  2.0710,  1.0938,  0.0751, -1.1806, -2.5052,\n",
              "         -4.3661,  1.7290]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use `squeeze()` to remove all dimensions with 1 value in them"
      ],
      "metadata": {
        "id": "24z6OmV8gqT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q.shape, Q.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVdQ21w-gpbx",
        "outputId": "f8f98cbd-4548-488d-b037-dcdc1a6f87f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 10, 1, 4]), torch.Size([10, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We scale the scores.\n",
        "\n",
        "This prevents gradients from vanishing and hence promotes stable training"
      ],
      "metadata": {
        "id": "JaBjKyx1TI4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scale = 1/sqrt(d_q)\n",
        "scale"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S-MRJylSlAt",
        "outputId": "9ddb95d1-8c9e-42f8-ac79-b5aba169c9e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scale * scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu2_95gBTXb7",
        "outputId": "31d7c195-6868-4a36-910f-93c24cba8676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.4918,  0.5051, -0.7328, -0.9076, -0.2914,  0.0247,  0.3871,\n",
              "           -0.6672,  0.8404,  0.0477],\n",
              "          [-0.6376, -0.1908, -0.1684,  0.9507,  0.1948, -0.0907, -0.6103,\n",
              "           -0.2979, -1.3998,  0.2232],\n",
              "          [-0.6647, -0.6587,  0.7333,  0.5792,  0.6609,  0.2599,  0.0668,\n",
              "            0.3744, -0.7527,  0.4668],\n",
              "          [ 0.1408,  0.1915,  0.6051, -0.2495, -0.4038,  0.0036,  0.0934,\n",
              "            0.6442,  0.8330, -0.3974],\n",
              "          [ 0.0964,  0.0190,  1.0364,  0.9828, -0.7126, -0.4955, -0.9393,\n",
              "            1.5374, -0.0398, -1.2373],\n",
              "          [ 1.3599, -0.5705,  1.1517, -0.9838,  0.2689,  0.0182,  0.9513,\n",
              "            1.7407,  2.0592, -0.7542],\n",
              "          [-0.1701,  0.2080, -1.5861,  0.1652,  0.2244, -0.0926, -0.2835,\n",
              "           -1.6406, -1.2228,  0.6060],\n",
              "          [-2.0429, -0.0684,  1.4664,  0.2521,  0.2229,  0.9000,  0.3974,\n",
              "           -0.0187, -0.3741,  1.2553],\n",
              "          [ 1.2672,  0.8493,  0.0714, -0.0403, -1.5446, -0.8434, -0.8377,\n",
              "            1.1624,  1.3161, -1.9414],\n",
              "          [-0.9995, -0.2237, -0.8627,  1.0355,  0.5469,  0.0376, -0.5903,\n",
              "           -1.2526, -2.1831,  0.8645]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And apply a softmax across the key dimension.\n",
        "\n",
        "So the sum of each row is 1."
      ],
      "metadata": {
        "id": "qe_RhvKuTRR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.softmax(scale * scores, dim=-1)\n",
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwo2ii4jTU5N",
        "outputId": "478f7581-f846-4205-af92-7a25d41b8dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.1447, 0.1466, 0.0425, 0.0357, 0.0661, 0.0907, 0.1303, 0.0454,\n",
              "           0.2051, 0.0928],\n",
              "          [0.0545, 0.0852, 0.0871, 0.2668, 0.1253, 0.0942, 0.0560, 0.0765,\n",
              "           0.0254, 0.1289],\n",
              "          [0.0404, 0.0407, 0.1637, 0.1403, 0.1522, 0.1019, 0.0840, 0.1143,\n",
              "           0.0370, 0.1254],\n",
              "          [0.0912, 0.0960, 0.1451, 0.0617, 0.0529, 0.0795, 0.0870, 0.1509,\n",
              "           0.1823, 0.0533],\n",
              "          [0.0734, 0.0679, 0.1879, 0.1781, 0.0327, 0.0406, 0.0260, 0.3101,\n",
              "           0.0640, 0.0193],\n",
              "          [0.1447, 0.0210, 0.1175, 0.0139, 0.0486, 0.0378, 0.0962, 0.2117,\n",
              "           0.2912, 0.0175],\n",
              "          [0.0970, 0.1416, 0.0235, 0.1356, 0.1439, 0.1048, 0.0866, 0.0223,\n",
              "           0.0339, 0.2108],\n",
              "          [0.0076, 0.0547, 0.2540, 0.0754, 0.0733, 0.1442, 0.0872, 0.0575,\n",
              "           0.0403, 0.2057],\n",
              "          [0.2210, 0.1455, 0.0668, 0.0598, 0.0133, 0.0268, 0.0269, 0.1990,\n",
              "           0.2321, 0.0089],\n",
              "          [0.0351, 0.0762, 0.0402, 0.2683, 0.1646, 0.0989, 0.0528, 0.0272,\n",
              "           0.0107, 0.2261]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0FIo3F2TLi-",
        "outputId": "b80fe482-025e-4af0-90c2-3a30537778f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In other words, the affinitiy for each query i across all keys j should now sum to 1.\n"
      ],
      "metadata": {
        "id": "82pDq77XTeS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A.sum(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwRwRwSTTNgk",
        "outputId": "5807a23a-ff24-4b66-8a4c-696fb5017c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "          1.0000, 1.0000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`v` is the multiplication of the attention matrix with the value matrix.\n"
      ],
      "metadata": {
        "id": "nB8lU9pETjko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = torch.einsum(\"bhls,bshd->blhd\", A, V)\n",
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqw3y123Tg-c",
        "outputId": "9608282f-0107-41dc-bfc2-9d7c3fcc8a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.2121, -0.6374,  0.1187,  0.2179]],\n",
              "\n",
              "         [[ 0.4360, -0.4998, -0.3921, -0.2926]],\n",
              "\n",
              "         [[ 0.4121, -0.2484,  0.0373, -0.0361]],\n",
              "\n",
              "         [[ 0.2643, -0.3929,  0.2992,  0.1209]],\n",
              "\n",
              "         [[ 0.4075, -0.3508,  0.2866, -0.1352]],\n",
              "\n",
              "         [[ 0.2616, -0.3893,  0.3912,  0.1565]],\n",
              "\n",
              "         [[ 0.3146, -0.5593, -0.1781, -0.0128]],\n",
              "\n",
              "         [[ 0.5706,  0.0008,  0.1774,  0.0079]],\n",
              "\n",
              "         [[ 0.1821, -0.5857,  0.3143,  0.0102]],\n",
              "\n",
              "         [[ 0.4354, -0.4904, -0.5414, -0.3290]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the equivalent of the following matrix operation\n"
      ],
      "metadata": {
        "id": "NikWC9MyTvqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(A.squeeze(),V.squeeze())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QClyPGxTsWx",
        "outputId": "abec4f0d-a80f-4304-826f-2f16d1d99dc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2121, -0.6374,  0.1187,  0.2179],\n",
              "        [ 0.4360, -0.4998, -0.3921, -0.2926],\n",
              "        [ 0.4121, -0.2484,  0.0373, -0.0361],\n",
              "        [ 0.2643, -0.3929,  0.2992,  0.1209],\n",
              "        [ 0.4075, -0.3508,  0.2866, -0.1352],\n",
              "        [ 0.2616, -0.3893,  0.3912,  0.1565],\n",
              "        [ 0.3146, -0.5593, -0.1781, -0.0128],\n",
              "        [ 0.5706,  0.0008,  0.1774,  0.0079],\n",
              "        [ 0.1821, -0.5857,  0.3143,  0.0102],\n",
              "        [ 0.4354, -0.4904, -0.5414, -0.3290]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This too has the number of operations proportional to quadratic of the input sequence length (10 mutliplications and 9 additions for every spot in the 10 x 4 matrix).\n",
        "\n",
        "Overall the 2 main matrix operations (multiplying query and key matricies and then multiplying the scaled output with the value matrix)  are quadratic in input sequence length in both space and time.\n",
        "\n",
        "This can become challenging when dealing with longer sequences."
      ],
      "metadata": {
        "id": "tZzLS232T08P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ProbAttention"
      ],
      "metadata": {
        "id": "F_OqOTZQT-Z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To deal with this issue, we can decrease the number of multiplication operations by multiplying some subset of the queries $ \\bar Q \\subseteq Q$\n",
        "\n",
        "$$\n",
        "\\text{Prob Sparse Attention} = \\text{softmax} \\bigg( \\frac{\\bar Q.K^T}{\\sqrt d_q} \\bigg).V\n",
        "$$"
      ],
      "metadata": {
        "id": "24QMLwNtYEU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_heads = 1 # Assume single head attention\n",
        "batch_size = 1 # Assume single batch size\n",
        "sequence_length = L_Q = L_K = L_V = 10 # Number of datapoints passed in parallel\n",
        "d_model = 4 # Number of features per data point\n",
        "\n",
        "d_k = d_model // n_heads\n",
        "d_v = d_model // n_heads\n",
        "d_q = d_model // n_heads\n",
        "\n",
        "Q = torch.randn( (batch_size, L_Q, n_heads, d_q) )\n",
        "K = torch.randn( (batch_size, L_K, n_heads, d_k) )\n",
        "V = torch.randn( (batch_size, L_V, n_heads, d_v) )\n",
        "\n",
        "Q.shape, K.shape, V.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as3xKSHuTxwH",
        "outputId": "64ac1e00-e7cb-4395-e6a5-a1dac7cefec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 10, 1, 4]),\n",
              " torch.Size([1, 10, 1, 4]),\n",
              " torch.Size([1, 10, 1, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q = Q.transpose(2, 1)\n",
        "K = K.transpose(2, 1)\n",
        "V = V.transpose(2, 1)\n",
        "Q.shape, K.shape, V.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWSbPJtxUQWp",
        "outputId": "7b0624ac-7348-40df-e3b5-86a546d91dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 10, 4]),\n",
              " torch.Size([1, 1, 10, 4]),\n",
              " torch.Size([1, 1, 10, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's determine the size of the subset of datapoints during probabilistic attention.\n",
        "\n",
        "- `L_Q_bar`: This is the number of query vectors we select of the total query vectors to attend.\n",
        "- `L_K_bar`: This is the number of key vectors we select. Note this is used internally to determine the subset of query vectors in under quadratic time/space complexity. In practice, we are attending on all keys but only a subset of query vectors."
      ],
      "metadata": {
        "id": "oZmcrGf6UV5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "factor = 2 # multiplier\n",
        "L_K_bar = factor * np.ceil(np.log(L_K)).astype('int').item() # U_part = factor * ln(L_k)\n",
        "L_Q_bar= factor * np.ceil(np.log(L_Q)).astype('int').item() # u = factor * ln(L_q)\n",
        "L_Q_bar, L_K_bar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcdwCeK6Ucms",
        "outputId": "6e03e453-1e16-4024-84d6-15a88a367ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For very short sequences, we will perform full attention.\n",
        "\n",
        "For long sequences, we likely perform probabilistic attention on a subset of query data points across all keys"
      ],
      "metadata": {
        "id": "sOlFml5jUwyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L_K_bar = L_K_bar if L_K_bar < L_K else L_K\n",
        "L_Q_bar = L_Q_bar if L_Q_bar < L_Q else L_Q\n",
        "L_Q_bar, L_K_bar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rkmce0PUTQa",
        "outputId": "74600cbf-53f3-4fe2-c83b-2a11cbb56147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this point, we perform operations that will help us select the appropriate query vectors $\\bar Q$."
      ],
      "metadata": {
        "id": "UTw6IsJKU-XF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`K_expand`: Every query will have the same 10 x 4 key matrix.\n",
        "\n",
        "This is an initialization from which we will later extract specific key vectors for each query"
      ],
      "metadata": {
        "id": "yEt4snXHVCes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B, H, L_K, E = K.shape\n",
        "_, _, L_Q, _ = Q.shape\n",
        "# unsqueeze adds dimension, expand with reshape\n",
        "K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n",
        "K_expand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn3xzLafVCvs",
        "outputId": "4014e93c-8623-4856-9505-8bde3b6daabd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[[ 1.1493, -0.8073, -0.4246, -1.2295],\n",
              "           [ 1.1640,  0.2684, -0.0041,  1.7503],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 0.4669,  0.5410, -1.4750, -1.9943],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [ 0.4741, -0.8833, -0.6060, -0.6919],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347]],\n",
              "\n",
              "          [[ 1.1493, -0.8073, -0.4246, -1.2295],\n",
              "           [ 1.1640,  0.2684, -0.0041,  1.7503],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 0.4669,  0.5410, -1.4750, -1.9943],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [ 0.4741, -0.8833, -0.6060, -0.6919],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347]],\n",
              "\n",
              "          [[ 1.1493, -0.8073, -0.4246, -1.2295],\n",
              "           [ 1.1640,  0.2684, -0.0041,  1.7503],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 0.4669,  0.5410, -1.4750, -1.9943],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [ 0.4741, -0.8833, -0.6060, -0.6919],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347]],\n",
              "\n",
              "          [[ 1.1493, -0.8073, -0.4246, -1.2295],\n",
              "           [ 1.1640,  0.2684, -0.0041,  1.7503],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 0.4669,  0.5410, -1.4750, -1.9943],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [ 0.4741, -0.8833, -0.6060, -0.6919],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347]],\n",
              "\n",
              "          [[ 1.1493, -0.8073, -0.4246, -1.2295],\n",
              "           [ 1.1640,  0.2684, -0.0041,  1.7503],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 0.4669,  0.5410, -1.4750, -1.9943],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [ 0.4741, -0.8833, -0.6060, -0.6919],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347]],\n",
              "\n",
              "          [[ 1.1493, -0.8073, -0.4246, -1.2295],\n",
              "           [ 1.1640,  0.2684, -0.0041,  1.7503],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 0.4669,  0.5410, -1.4750, -1.9943],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [ 0.4741, -0.8833, -0.6060, -0.6919],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347]],\n",
              "\n",
              "          [[ 1.1493, -0.8073, -0.4246, -1.2295],\n",
              "           [ 1.1640,  0.2684, -0.0041,  1.7503],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 0.4669,  0.5410, -1.4750, -1.9943],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [ 0.4741, -0.8833, -0.6060, -0.6919],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347]],\n",
              "\n",
              "          [[ 1.1493, -0.8073, -0.4246, -1.2295],\n",
              "           [ 1.1640,  0.2684, -0.0041,  1.7503],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 0.4669,  0.5410, -1.4750, -1.9943],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [ 0.4741, -0.8833, -0.6060, -0.6919],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347]],\n",
              "\n",
              "          [[ 1.1493, -0.8073, -0.4246, -1.2295],\n",
              "           [ 1.1640,  0.2684, -0.0041,  1.7503],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 0.4669,  0.5410, -1.4750, -1.9943],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [ 0.4741, -0.8833, -0.6060, -0.6919],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347]],\n",
              "\n",
              "          [[ 1.1493, -0.8073, -0.4246, -1.2295],\n",
              "           [ 1.1640,  0.2684, -0.0041,  1.7503],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 0.4669,  0.5410, -1.4750, -1.9943],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [ 0.4741, -0.8833, -0.6060, -0.6919],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347]]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_expand.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_16gcUgVEw3",
        "outputId": "08b7ae19-849a-46db-dcb9-1d7804065d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 10, 10, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For every query vector, we now select `L_K_bar` random key vectors.\n",
        "\n",
        "`index_sample`: matrix of shape (number of query items, subset of key items) where for each query, we are determining randomly with replacement the key vectors to consider attending on."
      ],
      "metadata": {
        "id": "NeZ3FaICVT0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_sample = torch.randint(L_K, (L_Q, L_K_bar))\n",
        "index_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQhg3vypVUDo",
        "outputId": "ef1877fc-6d90-4daa-b060-403d8611da27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4, 7, 2, 0, 8, 6],\n",
              "        [6, 9, 9, 4, 6, 2],\n",
              "        [8, 5, 9, 5, 9, 3],\n",
              "        [9, 2, 1, 9, 7, 2],\n",
              "        [9, 3, 4, 6, 8, 2],\n",
              "        [5, 6, 3, 2, 5, 9],\n",
              "        [6, 4, 7, 1, 1, 0],\n",
              "        [3, 0, 3, 0, 2, 7],\n",
              "        [6, 2, 2, 3, 9, 6],\n",
              "        [4, 7, 9, 2, 7, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_sample.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4ntWpuiVXnn",
        "outputId": "8bdec984-8dfb-4f34-e4f6-74967427c6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each query vector, we now only select the subset of key vectors to attend on using `index_sample`\n",
        "\n",
        "`K_sample`: Matrix where for each query, we select a subset of `L_K_bar` key vectors."
      ],
      "metadata": {
        "id": "vM8fv-zJVb1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n",
        " K_sample.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE8Sa7ClVZcz",
        "outputId": "45977227-dc20-4349-da24-3ff58a02617e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 10, 6, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX0abRQQVAbe",
        "outputId": "46149010-aa70-4ef0-b3b3-b66f81d02bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[[ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [ 1.1493, -0.8073, -0.4246, -1.2295],\n",
              "           [ 0.4741, -0.8833, -0.6060, -0.6919],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986]],\n",
              "\n",
              "          [[ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347],\n",
              "           [ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565]],\n",
              "\n",
              "          [[ 0.4741, -0.8833, -0.6060, -0.6919],\n",
              "           [ 0.4669,  0.5410, -1.4750, -1.9943],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347],\n",
              "           [ 0.4669,  0.5410, -1.4750, -1.9943],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504]],\n",
              "\n",
              "          [[-0.0110,  1.5004, -0.1369,  0.9347],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [ 1.1640,  0.2684, -0.0041,  1.7503],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565]],\n",
              "\n",
              "          [[-0.0110,  1.5004, -0.1369,  0.9347],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [ 0.4741, -0.8833, -0.6060, -0.6919],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565]],\n",
              "\n",
              "          [[ 0.4669,  0.5410, -1.4750, -1.9943],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [ 0.4669,  0.5410, -1.4750, -1.9943],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347]],\n",
              "\n",
              "          [[ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [ 1.1640,  0.2684, -0.0041,  1.7503],\n",
              "           [ 1.1640,  0.2684, -0.0041,  1.7503],\n",
              "           [ 1.1493, -0.8073, -0.4246, -1.2295]],\n",
              "\n",
              "          [[-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [ 1.1493, -0.8073, -0.4246, -1.2295],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [ 1.1493, -0.8073, -0.4246, -1.2295],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754]],\n",
              "\n",
              "          [[ 0.1041,  0.2502,  1.1637,  0.1986],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [-1.5922,  0.2786,  0.4121,  0.6504],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347],\n",
              "           [ 0.1041,  0.2502,  1.1637,  0.1986]],\n",
              "\n",
              "          [[ 0.3582,  0.3248, -2.1272, -1.5119],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [-0.0110,  1.5004, -0.1369,  0.9347],\n",
              "           [-0.8284, -0.2130, -1.0211, -0.2565],\n",
              "           [ 1.1851,  0.3053, -0.1947, -1.3754],\n",
              "           [ 0.4741, -0.8833, -0.6060, -0.6919]]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Q_K_sample`: For each query, we now determine an affinity score with each of the selected key vectors."
      ],
      "metadata": {
        "id": "QqbTxKXDVrcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n",
        "Q_K_sample.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBBoLGtiVqwD",
        "outputId": "4fc96918-a551-42a8-dbcb-a5068cb8e441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 10, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In detail, each 1 x 4 query vector is applied to a 4 x 6 key tensor to generate a 1 x 6 vector of query-key affinities."
      ],
      "metadata": {
        "id": "wYDJnnGCmDAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q.unsqueeze(-2).shape, K_sample.transpose(-2, -1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl8ctqBcl2AU",
        "outputId": "486cbefd-cd7a-49d4-f3da-3b58e5d6f7e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 10, 1, 4]), torch.Size([1, 1, 10, 4, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q_K_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URSl6CyVVvv0",
        "outputId": "753a9c15-724f-4251-ecf6-8de963538335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.1436,  1.3637, -0.7733,  1.7698,  0.9381,  0.4367],\n",
              "          [-2.3545,  1.2845,  1.2845,  3.7222, -2.3545,  2.6977],\n",
              "          [-0.0084,  0.4724,  0.7017,  0.4724,  0.7017, -1.4189],\n",
              "          [-1.3828, -0.1384, -3.6623, -1.3828,  1.2203, -0.1384],\n",
              "          [ 1.5805,  2.8538,  0.6118, -1.8568, -0.7366,  2.6788],\n",
              "          [-1.1198,  0.8741, -1.7703, -1.8456, -1.1198,  0.1116],\n",
              "          [ 2.8242, -4.4661,  0.3125, -1.4249, -1.4249, -0.2983],\n",
              "          [-0.8213,  2.5528, -0.8213,  2.5528,  1.4454,  1.9796],\n",
              "          [ 0.0983,  0.6171,  0.6171,  1.9412, -1.6207,  0.0983],\n",
              "          [-1.8467, -3.0208,  2.9274,  0.6800, -3.0208, -2.4974]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How did we get this shape:\n",
        "- `Q.unsqueeze(-2)` adds an extra dimension 1 from the last: 1 x 1 x 10 x 1 x 4\n",
        "- `K_sample.transpose(-2, -1)`: 1 x 1 x 10 x 4 x 6\n",
        "- matmul matrix multiply the last 2 dimensions: 1 x 1 x 10 x 1 x 6\n",
        "- `squeeze(-2)`: 1 x 1 x 10 x 6\n",
        "- This operation takes `O(L_Q.L_K_bar)` time complexity.\n",
        "\n",
        "`M(j)`: The largest affinity score divergence for query j."
      ],
      "metadata": {
        "id": "A5dCS8X-V0GI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ M= \\text{Max affinity of Q for any K} -\\text{Mean affinity of Q for any K} $$"
      ],
      "metadata": {
        "id": "xHDozqgnoIqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n",
        " M"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch-wUlnsVxqt",
        "outputId": "ba24b7ae-0f15-4815-f881-624e6453a4ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.4107, 3.2942, 0.6096, 1.7688, 2.3407, 1.3611, 3.2719, 1.8640,\n",
              "          1.7660, 3.6053]]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1.7698 - 0.3591"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtXftqAKo5Jk",
        "outputId": "0f98044d-ef1c-4ac7-c2bc-05ee05022c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4107"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VER1gJxJV5zr",
        "outputId": "44f854ef-eb72-4669-8570-79e2f97348e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More on the operation:\n",
        "- find the Top_k query with sparisty measurement\n",
        "- `Q_K_sample.max(-1)[0]`: finds the maximum k value for every query\n",
        "- `Q_K_sample.sum(-1) / L_K`: finds the mean of k value for every query\n",
        "- Each operation thus involes `O(L_Q.L_K_bar)` multiplications\n",
        "\n",
        "`M_top`: Index of the subset of `L_Q_bar` queries with the highest affinitiy spreads."
      ],
      "metadata": {
        "id": "WE26A-BAV9Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M.topk(L_Q_bar, sorted=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPP5UbjxpvIv",
        "outputId": "9f401f79-5685-4e49-9859-81b9d1ea2c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(\n",
              "values=tensor([[[3.2942, 3.6053, 2.3407, 3.2719, 1.8640, 1.7688]]]),\n",
              "indices=tensor([[[1, 9, 4, 6, 7, 3]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M_top = M.topk(L_Q_bar, sorted=False)[1]\n",
        "M_top.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2VEzPUKWG2t",
        "outputId": "640980b2-9634-4c97-cfdd-42fda05af6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M_top"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPZByKMYppKd",
        "outputId": "035315b6-7a84-4eb0-e55e-f84dd9f1ac25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 9, 4, 6, 7, 3]]])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Q_bar`: Subset of query vectors determined by `L_Q_bar`."
      ],
      "metadata": {
        "id": "CyeQm6cQWKhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q_bar = Q[\n",
        "    torch.arange(B)[:, None, None],\n",
        "    torch.arange(H)[None, :, None],\n",
        "    M_top,\n",
        "    :\n",
        "]\n",
        "Q_bar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kTQrlhgWK7s",
        "outputId": "a96c91b8-7563-424e-9032-577844636df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.8949,  0.4277, -2.0982,  0.3700],\n",
              "          [-1.4002,  1.1498, -0.0857,  1.2573],\n",
              "          [-1.6022, -0.1021, -1.7010,  1.5870],\n",
              "          [-0.1238, -0.0730,  2.5755, -0.7146],\n",
              "          [-0.5048, -0.6817, -0.3681, -1.9735],\n",
              "          [-0.7324,  0.1899,  1.1001, -1.6319]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q_bar.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWnrd2jyWMzu",
        "outputId": "e6f12e6b-675f-4a56-b28b-d34ab172a669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 6, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Q_bar_K`: Each entry is an affinity score between the subset of queries (that have the highest affinity spreads) and all keys."
      ],
      "metadata": {
        "id": "YmMoyQKGWUu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q_bar_K = torch.matmul(Q_bar, K.transpose(-2, -1))\n",
        "Q_bar_K"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1CFcCjIWVL0",
        "outputId": "b93930c0-5c4f-475e-8ba2-f1c7fe3c5d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.9378, -0.2707,  2.6977,  0.9200,  3.7222,  2.1705, -2.3545,\n",
              "           -1.0304,  0.2136,  1.2845],\n",
              "          [-4.0469,  0.8800,  0.6800,  3.3320, -1.8467, -2.4127,  0.2918,\n",
              "           -3.0208, -2.4974,  2.9274],\n",
              "          [-2.9880,  0.8924,  2.6788,  2.8538,  0.6118, -1.4594, -1.8568,\n",
              "           -3.7816, -0.7366,  1.5805],\n",
              "          [-0.2983, -1.4249, -2.3284,  0.7732, -4.4661, -2.4709,  2.8242,\n",
              "            0.3125, -1.0606, -1.1285],\n",
              "          [ 2.5528, -4.2234,  1.4454, -0.8213,  3.3646,  3.8742, -1.0433,\n",
              "            1.9796,  1.9514, -2.8115],\n",
              "          [ 0.5441, -3.6623, -0.1384,  0.6110, -0.0735,  1.3926,  0.9275,\n",
              "            1.2203, -0.0525, -1.3828]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q_bar.shape, K.shape, Q_bar_K.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDdupJryWXtJ",
        "outputId": "e360fe36-7c6d-421d-855a-fae19ea50fa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 6, 4]),\n",
              " torch.Size([1, 1, 10, 4]),\n",
              " torch.Size([1, 1, 6, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This matrix multiplication has 4 multiplications and 3 additions for every 6 x 10 cell.\n",
        "\n",
        "Hence there are `O(L_Q_bar . L_K)` operations performed.\n",
        "\n",
        "Scale by mutliplying with $ \\frac{1}{\\sqrt d_q}$"
      ],
      "metadata": {
        "id": "yNnHjvAMWc-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q_bar_K = 1./sqrt(d_q) * Q_bar_K\n",
        "Q_bar_K"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLtcOzJvWaT5",
        "outputId": "d3ada7fe-fbbe-4a99-ea25-b062fbd565b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.4689, -0.1353,  1.3489,  0.4600,  1.8611,  1.0853, -1.1772,\n",
              "           -0.5152,  0.1068,  0.6422],\n",
              "          [-2.0235,  0.4400,  0.3400,  1.6660, -0.9234, -1.2063,  0.1459,\n",
              "           -1.5104, -1.2487,  1.4637],\n",
              "          [-1.4940,  0.4462,  1.3394,  1.4269,  0.3059, -0.7297, -0.9284,\n",
              "           -1.8908, -0.3683,  0.7902],\n",
              "          [-0.1491, -0.7124, -1.1642,  0.3866, -2.2331, -1.2355,  1.4121,\n",
              "            0.1563, -0.5303, -0.5643],\n",
              "          [ 1.2764, -2.1117,  0.7227, -0.4107,  1.6823,  1.9371, -0.5217,\n",
              "            0.9898,  0.9757, -1.4057],\n",
              "          [ 0.2721, -1.8312, -0.0692,  0.3055, -0.0367,  0.6963,  0.4637,\n",
              "            0.6102, -0.0263, -0.6914]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now perform the softmax operation to scale these scores and get the attention matrix"
      ],
      "metadata": {
        "id": "VFa2uoI8Wmz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn = torch.softmax(Q_bar_K, dim=-1)\n",
        "attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAF1IyeVWkZX",
        "outputId": "93a7c533-5dc6-4392-89dd-1cc2af35226f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0309, 0.0431, 0.1903, 0.0782, 0.3176, 0.1462, 0.0152, 0.0295,\n",
              "           0.0550, 0.0939],\n",
              "          [0.0088, 0.1031, 0.0933, 0.3512, 0.0264, 0.0199, 0.0768, 0.0147,\n",
              "           0.0190, 0.2869],\n",
              "          [0.0149, 0.1038, 0.2536, 0.2768, 0.0902, 0.0320, 0.0263, 0.0100,\n",
              "           0.0460, 0.1464],\n",
              "          [0.0864, 0.0492, 0.0313, 0.1477, 0.0108, 0.0292, 0.4119, 0.1173,\n",
              "           0.0591, 0.0571],\n",
              "          [0.1438, 0.0049, 0.0826, 0.0266, 0.2157, 0.2784, 0.0238, 0.1079,\n",
              "           0.1064, 0.0098],\n",
              "          [0.1128, 0.0138, 0.0802, 0.1166, 0.0828, 0.1724, 0.1366, 0.1581,\n",
              "           0.0837, 0.0430]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLNsu-Z6WwyY",
        "outputId": "2ee3a2f7-b384-4776-c87b-5f8b564da20f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 6, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "get the context (every 100 vectors is the same 64 dim mean value vector)"
      ],
      "metadata": {
        "id": "u7goEcGoW4Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "V, V.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lU8jx2AW4_l",
        "outputId": "93a9171b-b4d3-45b4-96e4-1b8b9f974f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[ 2.7265, -0.9099, -0.4123,  0.2838],\n",
              "           [-0.1987, -0.1942, -0.8162,  0.7390],\n",
              "           [-1.3244, -1.2526,  0.6507, -0.7998],\n",
              "           [-1.2643, -0.2841,  1.3642,  0.1140],\n",
              "           [-0.7225, -2.2770, -1.2280, -1.1679],\n",
              "           [-1.3774, -1.1384, -0.7864, -0.5385],\n",
              "           [ 0.1696,  1.4029, -0.4873,  1.9040],\n",
              "           [ 0.4020, -0.0779,  0.4436, -0.9891],\n",
              "           [ 0.5908, -0.2860,  1.2081,  1.6977],\n",
              "           [-0.2286, -0.9445, -0.6943, -0.2456]]]]),\n",
              " torch.Size([1, 1, 10, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now initialize the value vectors. These are the vectors for every data point that will be propagated through the architecture in the event they are not selected in `M_top`."
      ],
      "metadata": {
        "id": "Q0I3LWdgXBiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "V_mean = V.mean(dim=-2)\n",
        "V_mean, V_mean.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEtkbWwaW8NL",
        "outputId": "35dc05de-bd71-4f25-ba72-898102ac1529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-0.1227, -0.5962, -0.0758,  0.0998]]]), torch.Size([1, 1, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`values`: its the same \"average value vector\" for query."
      ],
      "metadata": {
        "id": "jbijMkDWXJtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values = V_mean.unsqueeze(-2).expand(B, H, L_Q, V_mean.shape[-1]).clone()\n",
        "values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boDgdLrEXEOe",
        "outputId": "15b6f002-8150-45ce-9e5c-22b78364ab70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.1227, -0.5962, -0.0758,  0.0998],\n",
              "          [-0.1227, -0.5962, -0.0758,  0.0998],\n",
              "          [-0.1227, -0.5962, -0.0758,  0.0998],\n",
              "          [-0.1227, -0.5962, -0.0758,  0.0998],\n",
              "          [-0.1227, -0.5962, -0.0758,  0.0998],\n",
              "          [-0.1227, -0.5962, -0.0758,  0.0998],\n",
              "          [-0.1227, -0.5962, -0.0758,  0.0998],\n",
              "          [-0.1227, -0.5962, -0.0758,  0.0998],\n",
              "          [-0.1227, -0.5962, -0.0758,  0.0998],\n",
              "          [-0.1227, -0.5962, -0.0758,  0.0998]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-rBIm3IXMOz",
        "outputId": "1cf13dba-169c-45ac-a423-12a547e87fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 10, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`values`: Only the subset of query vectors determined by `M_top` are over ridden. The context of other vectors remains the same as the \"average of value vectors\""
      ],
      "metadata": {
        "id": "E8BrrDDrXSQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values[\n",
        "    torch.arange(B)[:, None, None],\n",
        "    torch.arange(H)[None, :, None],\n",
        "    M_top,\n",
        "    :\n",
        "] = torch.matmul(attn, V).type_as(values)"
      ],
      "metadata": {
        "id": "zYtIfOYTXS62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOX_NxLBXVK4",
        "outputId": "ac498ed3-5a83-4854-c37d-9b16051d58f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.1227, -0.5962, -0.0758,  0.0998],\n",
              "          [-0.6807, -1.2721, -0.3155, -0.4823],\n",
              "          [-0.1227, -0.5962, -0.0758,  0.0998],\n",
              "          [-0.1197, -0.5089, -0.0089,  0.0370],\n",
              "          [-0.7728, -0.7873,  0.2613, -0.1308],\n",
              "          [-0.1227, -0.5962, -0.0758,  0.0998],\n",
              "          [ 0.0886,  0.2708, -0.0070,  0.7789],\n",
              "          [-0.1833, -1.0657, -0.2990, -0.3037],\n",
              "          [-0.1227, -0.5962, -0.0758,  0.0998],\n",
              "          [-0.6459, -0.4971,  0.1969,  0.0962]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M_top, attn.shape, V.shape, torch.matmul(attn, V).shape, values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg4CO-8jXXId",
        "outputId": "11722b13-25f8-4d4e-ca77-7bdd42ef70d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 9, 4, 6, 7, 3]]]),\n",
              " torch.Size([1, 1, 6, 10]),\n",
              " torch.Size([1, 1, 10, 4]),\n",
              " torch.Size([1, 1, 6, 4]),\n",
              " torch.Size([1, 1, 10, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The matrix multiplcation of `attn` and `V` requires `O(L_Q_bar.L_K)` multiplication operations."
      ],
      "metadata": {
        "id": "ltdIyRur3tKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice only the rows indexed by `M_top` have been over ridden."
      ],
      "metadata": {
        "id": "x502BPg0Xbm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = values.transpose(2, 1).contiguous()\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WtUp04fXcGf",
        "outputId": "f0449ec1-fb4e-42a5-8a2e-f6522a0e5ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.1227, -0.5962, -0.0758,  0.0998]],\n",
              "\n",
              "         [[-0.6807, -1.2721, -0.3155, -0.4823]],\n",
              "\n",
              "         [[-0.1227, -0.5962, -0.0758,  0.0998]],\n",
              "\n",
              "         [[-0.1197, -0.5089, -0.0089,  0.0370]],\n",
              "\n",
              "         [[-0.7728, -0.7873,  0.2613, -0.1308]],\n",
              "\n",
              "         [[-0.1227, -0.5962, -0.0758,  0.0998]],\n",
              "\n",
              "         [[ 0.0886,  0.2708, -0.0070,  0.7789]],\n",
              "\n",
              "         [[-0.1833, -1.0657, -0.2990, -0.3037]],\n",
              "\n",
              "         [[-0.1227, -0.5962, -0.0758,  0.0998]],\n",
              "\n",
              "         [[-0.6459, -0.4971,  0.1969,  0.0962]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32CnriGmXdtm",
        "outputId": "6de946cd-f11f-48be-9003-919efd5442a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = out.view(batch_size, sequence_length, -1)"
      ],
      "metadata": {
        "id": "NJJ4BeB3Xpoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`out`: each entry is the output embedding for every data point"
      ],
      "metadata": {
        "id": "msT07AhTXsUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17DclPKlXqBQ",
        "outputId": "604d8031-7f1b-410b-9a21-58ecb80ec02b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost Analysis"
      ],
      "metadata": {
        "id": "aEzTT6SLXxcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cost of operations is the following:\n",
        "- Cost of generating `Q_K_sample`: O(L_Q.L_K_bar)\n",
        "- Cost of generating `M_top`: O(L_Q.L_K_bar)\n",
        "- Cost of generating `Q_bar_K`: O(L_Q_bar.L_K)\n",
        "- Cost of `attn.V`: O(L_Q_bar.L_K)\n",
        "\n",
        "\n",
        "Total cost = O( 2.L_Q.L_K_bar + 2.L_Q_bar. L_K)\n",
        "\n",
        "But, let L = L_Q = L_K.\n",
        "\n",
        "Then L_Q_bar = L_K_bar = c log L = O(log L).\n",
        "\n",
        "Then Total cost = O( 2 Llog L + 2 Llog L )\n",
        "\n",
        "**Total cost = O( L log L )**\n",
        "\n",
        "Hence PropSparse attention can perform similar attention to Full Attention but with lower time and space complexity O( L^2 ) vs O( L log L )"
      ],
      "metadata": {
        "id": "HJkzYNd9X7_M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tWbqkIsdXusJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}